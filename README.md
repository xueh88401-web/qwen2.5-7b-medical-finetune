# Qwen2.5-7B åŒ»å­¦åŠ©æ‰‹ (LoRAå¾®è°ƒç‰ˆ) - é¡¹ç›®ä»“åº“

[![GitHub](https://img.shields.io/github/license/xueh88401-web/qwen2.5-7b-medical-finetune)](LICENSE)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Model%20on%20HF-yellow)](https://huggingface.co/xueh88401/qwen2.5-7b-medical)

> æ­¤GitHubä»“åº“åŒ…å«äº†æ¨¡å‹çš„LoRAé€‚é…å™¨æ–‡ä»¶ã€è®­ç»ƒé…ç½®åŠä½¿ç”¨ç¤ºä¾‹ã€‚æ¨¡å‹ä¸»è¦æ‰˜ç®¡åœ¨HuggingFaceã€‚

---
language:
  - zh
license: mit
tags:
  - medical
  - qwen
  - lora
  - fine-tuned
base_model: Qwen/Qwen2.5-7B-Instruct
datasets:
  - CMKRG/QiZhenGPT
---

# Qwen2.5-7B åŒ»ç–—å¤§æ¨¡å‹å¾®è°ƒ

ä½¿ç”¨ QLoRA æŠ€æœ¯åœ¨ **QiZhenGPT** åŒ»ç–—æ•°æ®é›†ä¸Šå¯¹ Qwen2.5-7B-Instruct è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œæå‡å…¶åœ¨åŒ»ç–—é—®ç­”ä¸­çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ã€‚

## è®­ç»ƒè¯¦æƒ…
- **æ–¹æ³•**: QLoRA (4-bit NF4 + LoRA, r=8)
- **æ•°æ®**: [QiZhenGPT](https://github.com/CMKRG/QiZhenGPT) (~20k æ ·æœ¬)
- **æ¡†æ¶**: LLaMA-Factory
- **è®­ç»ƒæ—¶é•¿**: 6.8 å°æ—¶ (6750 steps)
- **éªŒè¯æŸå¤±**: 1.578 (ä¸‹é™ 23.8%)

## ä½¿ç”¨è¯´æ˜
æœ¬ä»“åº“æä¾›çš„æ˜¯ LoRA é€‚é…å™¨æƒé‡ï¼Œéœ€è¦ä¸åŸºç¡€æ¨¡å‹ `Qwen/Qwen2.5-7B-Instruct` ç»“åˆä½¿ç”¨ã€‚

### ä½¿ç”¨ Transformers + PEFT åŠ è½½

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# åŠ è½½åŸºç¡€æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto"
)
# åŠ è½½æœ¬ LoRA é€‚é…å™¨
model = PeftModel.from_pretrained(model, "xueh88401/qwen2.5-7b-medical")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

# è¿›è¡Œæ¨ç†
inputs = tokenizer("ç”¨æˆ·ï¼šæ„Ÿå†’äº†æ€ä¹ˆåŠï¼Ÿ\nåŠ©æ‰‹ï¼š", return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=200)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))

---
## ğŸ“ æœ¬GitHubä»“åº“æ–‡ä»¶è¯´æ˜

æ­¤ä»“åº“ä½œä¸ºHuggingFaceæ¨¡å‹é¡µé¢çš„è¡¥å……ï¼Œæä¾›å®Œæ•´çš„é¡¹ç›®æ–‡ä»¶ä»¥ä¾¿å¤ç°å’Œç ”ç©¶ï¼š
```
.
â”œâ”€â”€ README.md                 # æœ¬è¯´æ˜æ–‡ä»¶
â”œâ”€â”€ inference_demo.py         # ç®€æ˜“æ¨ç†è„šæœ¬
â”œâ”€â”€ adapter/                  # LoRAé€‚é…å™¨æƒé‡ä¸ç›¸å…³æ–‡ä»¶
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â””â”€â”€ ...
â””â”€â”€ training/                 # è®­ç»ƒé…ç½®æ–‡ä»¶
    â””â”€â”€ your_training_config.yaml
```
è¦ä½¿ç”¨æ¨¡å‹ï¼Œå»ºè®®ç›´æ¥è®¿é—® [HuggingFaceæ¨¡å‹é¡µé¢](https://huggingface.co/xueh88401/qwen2.5-7b-medical)ã€‚